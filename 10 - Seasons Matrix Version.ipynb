{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from utilities import *\n",
    "import numpy as np\n",
    "from numpy import dot\n",
    "\n",
    "def norm_vec(v):\n",
    "    return v / np.linalg.norm(v)\n",
    "np.set_printoptions(precision=3)\n",
    "\n",
    "from sympy import *\n",
    "init_printing()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1>Seasons Represented as Matrices</h1>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we are going to do much of what is in Notebook 9 from a slightly different perspective. Namely, we are going to take all of the document vectors for the corpus, and think of them as the columns in one big matrix.\n",
    "\n",
    "There are a couple of reasons to do this:\n",
    "\n",
    "1. The less interesting reason: It can make it possible for us to write more compact code.\n",
    "2. The more interesting reason: Creating matrices in this manner provides new ways to conceptualize what we're doing. These new conceptualizations provide launching points for more advanced algorithms. (We won't get to these more advanced algorithms today)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Bruce: Go back to the slides here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get everything ready, pretty much as before"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Load the corpus**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from seasons_module import load_seasons_corpus\n",
    "seasons_corpus = load_seasons_corpus()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Compile the vocabulary in the usual way.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "set_vocab = set([])\n",
    "for fname in seasons_corpus.keys():\n",
    "    set_vocab = set_vocab.union(set(seasons_corpus[fname][0]))\n",
    "f = open(\"lists/seasons_stop_list.txt\")\n",
    "stop_list = set(f.read().split(\"\\n\"))\n",
    "pruned_vocab = set(sorted([w for w in list(set_vocab) if w not in stop_list]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Compute the corpus and document frequency for each term.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "word_fdist = nltk.FreqDist() # the corpus frequences\n",
    "doc_fdist = nltk.FreqDist()# the document frequencies\n",
    "for word in pruned_vocab:\n",
    "    word_fdist[word] = 0\n",
    "    doc_fdist[word] = 0\n",
    "    for name in seasons_corpus.keys():\n",
    "        if word in seasons_corpus[name][0]:\n",
    "            doc_fdist[word] += 1\n",
    "            word_fdist[word] += seasons_corpus[name][0].count(word)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create a very small vocabulary \n",
    "\n",
    "Just 10 words, to make it more simple to understand what's going on."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "small_vocab = [w[0] for w in word_fdist.most_common(10)]\n",
    "print(small_vocab)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Compute the weighted document vector for each document**\n",
    "\n",
    "Same as before, but now using our smaller vocabulary."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def tf(tf, df, cf, N):\n",
    "    return tf\n",
    "\n",
    "def logtf(tf, df, cf, N):\n",
    "    if tf == 0:\n",
    "        result = 0\n",
    "    else:\n",
    "        result = (1 + np.log(tf))\n",
    "    return result\n",
    "\n",
    "def onehot(tf, df, cf, N):\n",
    "    if tf == 0:\n",
    "        return 0\n",
    "    else:\n",
    "        return 1\n",
    "\n",
    "def tfidf(tf, df, cf, N):\n",
    "    if tf == 0:\n",
    "        result = 0\n",
    "    else:\n",
    "        result = (1 + np.log(tf)) * np.log(N  / df)\n",
    "    return result\n",
    "\n",
    "def compute_vector(words, vocab, df, N, weight_function):\n",
    "    new_vector = []\n",
    "    for w in vocab:\n",
    "        tf = words.count(w)\n",
    "        new_vector.append(weight_function(tf, df[w], 0, N))\n",
    "    return norm_vec(np.array(new_vector))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# compute the document vector for each document\n",
    "doc_vectors = {}\n",
    "N = len(seasons_corpus.keys())\n",
    "wf = tf\n",
    "for fname in seasons_corpus.keys():\n",
    "    doc_vectors[fname] = compute_vector(seasons_corpus[fname][0], small_vocab, doc_fdist, N, wf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print(len(doc_vectors), len(doc_vectors['angelapre']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create a termxdocument matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is a matrix where every row corresponds to a word in the vocabulary, and every column corresponds to a document.\n",
    "\n",
    "Another way to say this: Each column in the matrix is the document vector for a document."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "td_matrix = np.zeros([len(small_vocab), len(doc_vectors)])\n",
    "i = 0\n",
    "name_index = {}\n",
    "name_list = []\n",
    "for name in doc_vectors.keys():\n",
    "    td_matrix[:, i] = doc_vectors[name]\n",
    "    name_index[name] = i\n",
    "    name_list += [name]\n",
    "    i = i + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "td_matrix.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def round_matrix(the_matrix, prec = 2):\n",
    "    sh = the_matrix.shape\n",
    "    if len(sh) == 1:\n",
    "        for i in range(sh[0]):\n",
    "            the_matrix[i] = round(the_matrix[i], prec)\n",
    "    else:\n",
    "        for i in range(sh[0]):\n",
    "            for j in range(sh[1]):\n",
    "                the_matrix[i, j] = round(the_matrix[i, j], prec)\n",
    "    return the_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "Matrix(round_matrix(td_matrix))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Document x document similarity"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can get the similarity of two documents by multiplying the termxdocument matrix by it's transpose."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "dd_matrix = np.dot(td_matrix.transpose(), td_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "dd_matrix.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "Matrix(round_matrix(dd_matrix))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Load the comparison vectors and build a matrix with them.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from seasons_module import load_seasons_comparison_files\n",
    "comparison_dict = load_seasons_comparison_files()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Compute vectors for the comparison documents\n",
    "comparison_vectors = {}\n",
    "for fname in comparison_dict.keys():\n",
    "    comparison_vectors[fname] = compute_vector(comparison_dict[fname], small_vocab, doc_fdist, N, wf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "ctd_matrix = np.zeros([len(small_vocab), len(comparison_vectors)])\n",
    "i = 0\n",
    "cdname_index = {}\n",
    "for name in comparison_vectors.keys():\n",
    "    ctd_matrix[:, i] = comparison_vectors[name]\n",
    "    cdname_index[name] = i\n",
    "    i = i + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "Matrix(round_matrix(ctd_matrix))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "Matrix(round_matrix(td_matrix.transpose()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can multiply the comparison matrix by the transpose of the termxdocument matrix in order to get the similarities between the student transcripts and the comparison documents."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "code_matrix = np.dot(td_matrix.transpose(), ctd_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "Matrix(round_matrix(code_matrix))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "inverted_cdname_index = dict(map(lambda item:(item[1],item[0]), cdname_index.items()))\n",
    "student_codes = {}\n",
    "for name in seasons_corpus.keys():\n",
    "    row = list(code_matrix[name_index[name]])\n",
    "    maxcode = row.index(max(row))\n",
    "    student_codes[name] = inverted_cdname_index[maxcode]\n",
    "print(student_codes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**How similar are our results to the codes assigned by human coders?**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def compute_accuracy():\n",
    "    number_right = 0\n",
    "    total_possible = 0\n",
    "    for name in student_codes.keys():\n",
    "        if seasons_corpus[name][1] != \"none\":\n",
    "            total_possible += 1\n",
    "            if student_codes[name] == seasons_corpus[name][1]:\n",
    "                number_right += 1\n",
    "    return 1.0 * number_right / total_possible"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "compute_accuracy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "gold_list = []\n",
    "test_list = []\n",
    "for name in student_codes.keys():\n",
    "    if seasons_corpus[name][1] != \"none\":\n",
    "        gold_list += [seasons_corpus[name][1]]\n",
    "        test_list += [student_codes[name]]\n",
    "cm = nltk.ConfusionMatrix(gold_list, test_list)\n",
    "print(cm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
