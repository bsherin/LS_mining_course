{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Collocations and ngrams revisited"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Getting n-grams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "txt = \"now is the time for all good people to come to the aid of their country\".split()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "list(nltk.bigrams(txt))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "list(nltk.ngrams(txt, 3))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We **could** include bigrams, or even trigrams, as dimensions in our vectors, and redo all of the analyses we have already done. But there are a couple of patterns:\n",
    "\n",
    "* There will be a lot of ngrams.\n",
    "* Most of them won't appear all that often.\n",
    "\n",
    "That means we generally want to be strategic about which ones to include. We want only the good ones (whatever that means).\n",
    "\n",
    "Good ngrams are also interesting for other reasons."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load the civil war dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "American_Civil_War\n",
      "Abraham_Lincoln\n",
      "Slavery_in_the_United_States\n",
      "Slave_states_and_free_states\n",
      "Emancipation_Proclamation\n",
      "Robert_E._Lee\n",
      "Ulysses_S._Grant\n",
      "Conclusion_of_the_American_Civil_War\n",
      "Origins_of_the_American_Civil_War\n",
      "Issues_of_the_American_Civil_War\n"
     ]
    }
   ],
   "source": [
    "import wikipediaapi\n",
    "pages = [\n",
    "    \"American Civil War\",\n",
    "    \"Abraham Lincoln\",\n",
    "    \"Slavery in the United States\",\n",
    "    \"Slave states and free states\",\n",
    "    \"Emancipation Proclamation\",\n",
    "    \"Robert E. Lee\",\n",
    "    \"Ulysses S. Grant\",\n",
    "    \"Conclusion of the American Civil War\",\n",
    "    \"Origins of the American Civil War\",\n",
    "    \"Issues of the American Civil War\"\n",
    "]\n",
    "import re\n",
    "\n",
    "def underscorize(pagename):\n",
    "    return re.sub(\" \", \"_\", pagename)\n",
    "\n",
    "wiki_wiki = wikipediaapi.Wikipedia(\n",
    "        language='en',\n",
    "        extract_format=wikipediaapi.ExtractFormat.WIKI\n",
    ")\n",
    "page_dict = {}\n",
    "for page in pages:\n",
    "    pagename = underscorize(page)\n",
    "    print(pagename)\n",
    "    p_wiki = wiki_wiki.page(pagename)\n",
    "    page_text = p_wiki.text.split(\"\\n\")\n",
    "    page_paras = [para for para in page_text if len(para) > 1]\n",
    "    page_dict[pagename] = page_paras"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tokenize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_para(para):\n",
    "    sentences = nltk.sent_tokenize(para)\n",
    "    tokenized_sentences = []\n",
    "    for sent in sentences:\n",
    "        tokenized_sentence = nltk.word_tokenize(sent)\n",
    "        tokenized_sentences.append(tokenized_sentence)\n",
    "    return tokenized_sentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenized_sentences = []\n",
    "for pagename, page_paras in page_dict.items():\n",
    "    for para in page_paras:\n",
    "        tokenized_sentences += process_para(para)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create a bigram frequency distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "bigram_fdist = nltk.FreqDist()\n",
    "for sent in tokenized_sentences:\n",
    "    bigram_fdist.update(nltk.bigrams(sent))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bigram_fdist.most_common(25)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Finding meaningful collocations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Generally, we'd like to find collocations that appear more than would be expected."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "bigram_measures = nltk.collocations.BigramAssocMeasures()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "bigram_measures.raw_freq\n",
    "bigram_measures.chi_sq\n",
    "bigram_measures.likelihood_ratio\n",
    "bigram_measures.pmi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_documents = list(nltk.BigramCollocationFinder._build_new_documents(tokenized_sentences, 2, pad_right=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "finder = nltk.BigramCollocationFinder.from_words(new_documents, 2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### First, raw frequency"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('of', 'the'),\n",
       " ('in', 'the'),\n",
       " (',', 'and'),\n",
       " (',', 'the'),\n",
       " ('to', 'the'),\n",
       " ('and', 'the'),\n",
       " ('the', 'Union'),\n",
       " ('Civil', 'War'),\n",
       " (',', 'but'),\n",
       " ('the', 'South'),\n",
       " ('the', 'war'),\n",
       " ('for', 'the'),\n",
       " ('as', 'a'),\n",
       " ('that', 'the'),\n",
       " ('United', 'States'),\n",
       " ('on', 'the'),\n",
       " (',', 'which'),\n",
       " ('by', 'the'),\n",
       " (',', 'Grant'),\n",
       " ('at', 'the')]"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "finder.nbest(bigram_measures.raw_freq, 20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(('of', 'the'), 0.00985164242618555),\n",
       " (('in', 'the'), 0.006820367833513073),\n",
       " ((',', 'and'), 0.006660060042554432),\n",
       " ((',', 'the'), 0.0033227433035063684),\n",
       " (('to', 'the'), 0.0030822816170684077),\n",
       " (('and', 'the'), 0.002477484042088082),\n",
       " (('the', 'Union'), 0.0020038473869830073),\n",
       " (('Civil', 'War'), 0.0019455536448162289),\n",
       " ((',', 'but'), 0.0017415255472325046),\n",
       " (('the', 'South'), 0.001508350578565391),\n",
       " (('the', 'war'), 0.0014792037074820017),\n",
       " (('for', 'the'), 0.0014646302719403073),\n",
       " (('as', 'a'), 0.00145734355416946),\n",
       " (('that', 'the'), 0.0014500568363986126),\n",
       " (('United', 'States'), 0.0014136232475443762),\n",
       " (('on', 'the'), 0.0014136232475443762),\n",
       " ((',', 'which'), 0.0013553295053775978),\n",
       " (('by', 'the'), 0.0012606021743565828),\n",
       " ((',', 'Grant'), 0.0012241685855023463),\n",
       " (('at', 'the'), 0.0011585881255647206)]"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "finder.score_ngrams(bigram_measures.raw_freq)[:20]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Let's try filtering out stop_words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "f = open(\"lists/stop-words_english_1_en.txt\")\n",
    "stop_list = f.read().split(\"\\n\")\n",
    "stop_list += list('!\"#$%&\\'()*+,-./:;<=>?@[\\\\]^_`{|}~â€™')\n",
    "stop_list += list(\"abcdefghijklmnopqrstuvwxyz0123456789\")\n",
    "stop_list = set(stop_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "def filter_function(w,):\n",
    "    return w in stop_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "finder = nltk.BigramCollocationFinder.from_words(new_documents, 2)\n",
    "finder.nbest(bigram_measures.raw_freq, 20)\n",
    "finder.apply_word_filter(filter_function)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('Civil', 'War'),\n",
       " ('United', 'States'),\n",
       " ('Grant', \"'s\"),\n",
       " ('Lee', \"'s\"),\n",
       " ('Lincoln', \"'s\"),\n",
       " ('Emancipation', 'Proclamation'),\n",
       " ('South', 'Carolina'),\n",
       " ('New', 'York'),\n",
       " ('Abraham', 'Lincoln'),\n",
       " ('American', 'Civil'),\n",
       " ('E.', 'Lee'),\n",
       " ('Robert', 'E.'),\n",
       " ('``', 'The'),\n",
       " ('slave', 'states'),\n",
       " (\"'s\", 'army'),\n",
       " ('Republican', 'Party'),\n",
       " ('slave', 'trade'),\n",
       " ('Major', 'General'),\n",
       " ('New', 'Orleans'),\n",
       " ('free', 'states')]"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "finder.nbest(bigram_measures.raw_freq, 20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Other measures"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(\"'30s\", 'dozens'),\n",
       " (\"'ll\", 'hit'),\n",
       " (\"'their\", 'Moses'),\n",
       " ('--', '+Jacobs.pdf'),\n",
       " ('//amerautobiofa14.wiki.uml.edu/file/view/Excerpts+from+Incidents+in+the+Life+of+a+Slave+Girl+',\n",
       "  '--'),\n",
       " ('10:13', 'pm'),\n",
       " ('15,741', 'other/unknown'),\n",
       " ('1526.The', 'ill-fated'),\n",
       " ('181', 'high-slavery'),\n",
       " ('190,000', 'volunteered'),\n",
       " ('205', 'low-slavery'),\n",
       " ('29th', 'Ulto'),\n",
       " ('3,200', 'kg'),\n",
       " ('364â€”went', 'bankrupt.Congress'),\n",
       " ('43rd', 'Battalion'),\n",
       " ('533,000', 'battle-ready'),\n",
       " ('642-ton', 'iron-hulled'),\n",
       " ('728', 'acknowledging'),\n",
       " ('9780300192001.Scholarly', 'articlesTurner'),\n",
       " ('Adalberto', 'Aguirre')]"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "finder = nltk.BigramCollocationFinder.from_words(new_documents, 2)\n",
    "finder.nbest(bigram_measures.chi_sq, 20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('habeas', 'corpus'),\n",
       " ('Wilmot', 'Proviso'),\n",
       " ('Founding', 'Fathers'),\n",
       " ('â€™', 's'),\n",
       " ('Lost', 'Cause'),\n",
       " ('United', 'States'),\n",
       " ('Civil', 'War'),\n",
       " ('Supreme', 'Court'),\n",
       " ('Emancipation', 'Proclamation'),\n",
       " ('inaugural', 'address'),\n",
       " ('Dred', 'Scott'),\n",
       " ('Thirteenth', 'Amendment'),\n",
       " ('Ulysses', 'S.'),\n",
       " ('St.', 'Louis'),\n",
       " ('New', 'York'),\n",
       " ('Maj.', 'Gen.'),\n",
       " ('Eric', 'Foner'),\n",
       " ('Robert', 'E.'),\n",
       " ('Chief', 'Justice'),\n",
       " ('Fugitive', 'Slave')]"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "finder = nltk.BigramCollocationFinder.from_words(new_documents, 2)\n",
    "finder.apply_freq_filter(10)\n",
    "finder.nbest(bigram_measures.chi_sq, 20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('Civil', 'War'),\n",
       " ('United', 'States'),\n",
       " ('of', 'the'),\n",
       " ('in', 'the'),\n",
       " (',', 'and'),\n",
       " ('Emancipation', 'Proclamation'),\n",
       " ('New', 'York'),\n",
       " (',', 'but'),\n",
       " ('did', 'not'),\n",
       " ('the', 'Union'),\n",
       " ('Robert', 'E.'),\n",
       " ('South', 'Carolina'),\n",
       " ('as', 'a'),\n",
       " ('Grant', \"'s\"),\n",
       " ('Lee', \"'s\"),\n",
       " ('Abraham', 'Lincoln'),\n",
       " ('the', 'war'),\n",
       " ('the', 'United'),\n",
       " ('had', 'been'),\n",
       " (',', 'which')]"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "finder = nltk.BigramCollocationFinder.from_words(new_documents, 2)\n",
    "finder.apply_freq_filter(10)\n",
    "finder.nbest(bigram_measures.likelihood_ratio, 20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Using part of speech"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tagging a sentence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('now', 'RB'), ('is', 'VBZ'), ('the', 'DT'), ('time', 'NN'), ('for', 'IN'), ('all', 'DT'), ('good', 'JJ'), ('people', 'NNS'), ('to', 'TO'), ('come', 'VB'), ('to', 'TO'), ('the', 'DT'), ('aid', 'NN'), ('of', 'IN'), ('their', 'PRP$'), ('country', 'NN')]\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "sentence = \"now is the time for all good people to come to the aid of their country\"\n",
    "print(nltk.pos_tag(sentence.split()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nltk.help.upenn_tagset()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "   Note that everything we did with word vectors, \n",
    "   you can do with tagged words."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tag the entire civil war corpus"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that we have to separate it into sentences before tokenizing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "def process_para2(para):\n",
    "    sentences = nltk.sent_tokenize(para)\n",
    "    tagged_sentences = []\n",
    "    for sent in sentences:\n",
    "        tokenized_sentence = nltk.word_tokenize(sent)\n",
    "        tagged_sentence = nltk.pos_tag(tokenized_sentence)\n",
    "        tagged_sentences.append(tagged_sentence)\n",
    "    return tagged_sentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "tagged_sentences = []\n",
    "for pagename, page_paras in page_dict.items():\n",
    "    for para in page_paras:\n",
    "        tagged_sentences += process_para2(para)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's again get the most frequent bigrams."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "bigram_fdist2 = nltk.FreqDist()\n",
    "for sent in tagged_sentences:\n",
    "    bigram_fdist2.update(nltk.bigrams(sent))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[((('of', 'IN'), ('the', 'DT')), 1352),\n",
       " ((('in', 'IN'), ('the', 'DT')), 936),\n",
       " (((',', ','), ('and', 'CC')), 914),\n",
       " (((',', ','), ('the', 'DT')), 456),\n",
       " ((('to', 'TO'), ('the', 'DT')), 423),\n",
       " ((('and', 'CC'), ('the', 'DT')), 340),\n",
       " ((('the', 'DT'), ('Union', 'NNP')), 275),\n",
       " ((('Civil', 'NNP'), ('War', 'NNP')), 267),\n",
       " (((',', ','), ('but', 'CC')), 239),\n",
       " ((('the', 'DT'), ('South', 'NNP')), 207),\n",
       " ((('the', 'DT'), ('war', 'NN')), 203),\n",
       " ((('for', 'IN'), ('the', 'DT')), 201),\n",
       " ((('as', 'IN'), ('a', 'DT')), 200),\n",
       " ((('that', 'IN'), ('the', 'DT')), 199),\n",
       " ((('on', 'IN'), ('the', 'DT')), 194),\n",
       " ((('United', 'NNP'), ('States', 'NNPS')), 192),\n",
       " (((',', ','), ('which', 'WDT')), 186),\n",
       " ((('by', 'IN'), ('the', 'DT')), 173),\n",
       " (((',', ','), ('Grant', 'NNP')), 168),\n",
       " ((('at', 'IN'), ('the', 'DT')), 159),\n",
       " ((('the', 'DT'), ('United', 'NNP')), 154),\n",
       " ((('.', '.'), (\"''\", \"''\")), 152),\n",
       " ((('the', 'DT'), ('North', 'NNP')), 151),\n",
       " ((('as', 'IN'), ('the', 'DT')), 151),\n",
       " ((('of', 'IN'), ('slavery', 'NN')), 148)]"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bigram_fdist2.most_common(25)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Now let's filter on part of speech"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We want the first tag to be a noun or adjective, and the second tag to be a noun"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "def filter_on_pos(bg):\n",
    "    tag1 = bg[0][0][1]\n",
    "    tag2 = bg[0][1][1]\n",
    "    return re.search(\"^N.*\", tag2) and ((re.search(\"^N.*\", tag1) or re.search(\"^J.*\", tag1)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "((('Civil', 'NNP'), ('War', 'NNP')), 267)\n",
      "((('United', 'NNP'), ('States', 'NNPS')), 192)\n",
      "((('Emancipation', 'NNP'), ('Proclamation', 'NNP')), 80)\n",
      "((('South', 'NNP'), ('Carolina', 'NNP')), 78)\n",
      "((('New', 'NNP'), ('York', 'NNP')), 77)\n",
      "((('Abraham', 'NNP'), ('Lincoln', 'NNP')), 70)\n",
      "((('American', 'NNP'), ('Civil', 'NNP')), 66)\n",
      "((('E.', 'NNP'), ('Lee', 'NNP')), 65)\n",
      "((('Robert', 'NNP'), ('E.', 'NNP')), 64)\n"
     ]
    }
   ],
   "source": [
    "for bg in bigram_fdist2.most_common(100):\n",
    "    if filter_on_pos(bg):\n",
    "        print(bg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
